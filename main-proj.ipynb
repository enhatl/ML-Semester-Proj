{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/enhatl/ML-Semester-Proj/main/dataset.csv'\n",
    "df = pd.read_csv(url,index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt = df.copy() #make copy so that we can prepare the data correctly\n",
    "df_dt = df_dt.dropna(axis = 0) #remove na values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique variable, will not be useful to us\n",
    "df_dt = df_dt.drop('track_id', axis=1)\n",
    "#album name and track name are not going to be useful either\n",
    "df_dt = df_dt.drop(['album_name','track_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#artist name can be useful, but need to get them as numerical values\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "#We are assuming the first artist is the main artist and will give the most information.\n",
    "df_dt['artist_encoded'] = df_dt['artists'].str.split(',').str[0].str.strip()  #Extract first artist\n",
    "df_dt['artist_encoded'] = label_encoder.fit_transform(df_dt['artist_encoded'])  #Apply label encoding\n",
    "df_dt = df_dt.drop(['artists'], axis=1) #dont need artists column anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column names of the last and second to last columns\n",
    "last_column_name = df_dt.columns[-1]\n",
    "second_last_column_name = df_dt.columns[-2]\n",
    "\n",
    "# Swap the last and second to last columns while preserving column names\n",
    "df_dt[last_column_name], df_dt[second_last_column_name] = df_dt[second_last_column_name], df_dt[last_column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing\n",
    "array=df_dt.values                    # storing all the values in array, ready to be sliced\n",
    "X=array[:,0:16]                          # storing columns 1 to 13 in X\n",
    "y=array[:,16]                            # storing column 14 in Y\n",
    "scaler=MinMaxScaler(feature_range=(0,1)) # importing MinMaxScaler function and entering the range of scaled values (0,1)\n",
    "rescaledX=scaler.fit_transform(X)        # rescaling all the column values and storing them in rescaledX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(rescaledX[:,0:16], y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "tree_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         acoustic       0.12      0.12      0.12       191\n",
      "         afrobeat       0.20      0.19      0.19       206\n",
      "         alt-rock       0.05      0.02      0.03       405\n",
      "      alternative       0.13      0.12      0.12       217\n",
      "          ambient       0.20      0.20      0.20       212\n",
      "            anime       0.14      0.11      0.13       261\n",
      "      black-metal       0.47      0.43      0.45       237\n",
      "        bluegrass       0.32      0.29      0.30       217\n",
      "            blues       0.12      0.08      0.09       314\n",
      "           brazil       0.10      0.06      0.08       330\n",
      "        breakbeat       0.28      0.26      0.27       185\n",
      "          british       0.11      0.09      0.10       233\n",
      "         cantopop       0.24      0.24      0.24       205\n",
      "    chicago-house       0.43      0.35      0.39       236\n",
      "         children       0.28      0.33      0.30       172\n",
      "            chill       0.14      0.11      0.12       246\n",
      "        classical       0.57      0.50      0.53       235\n",
      "             club       0.22      0.22      0.22       179\n",
      "           comedy       0.80      0.78      0.79       186\n",
      "          country       0.46      0.52      0.49       195\n",
      "            dance       0.30      0.24      0.27       256\n",
      "        dancehall       0.15      0.17      0.16       171\n",
      "      death-metal       0.20      0.20      0.20       205\n",
      "       deep-house       0.12      0.08      0.10       267\n",
      "   detroit-techno       0.42      0.44      0.43       188\n",
      "            disco       0.13      0.12      0.13       221\n",
      "           disney       0.24      0.26      0.25       189\n",
      "    drum-and-bass       0.43      0.46      0.44       203\n",
      "              dub       0.08      0.05      0.06       314\n",
      "          dubstep       0.03      0.04      0.04       171\n",
      "              edm       0.05      0.04      0.04       296\n",
      "          electro       0.21      0.17      0.19       232\n",
      "       electronic       0.02      0.03      0.03       167\n",
      "              emo       0.13      0.12      0.13       214\n",
      "             folk       0.08      0.06      0.07       281\n",
      "            forro       0.34      0.34      0.34       200\n",
      "           french       0.19      0.18      0.18       199\n",
      "             funk       0.19      0.18      0.19       212\n",
      "           garage       0.09      0.10      0.09       183\n",
      "           german       0.30      0.30      0.30       211\n",
      "           gospel       0.25      0.29      0.27       196\n",
      "             goth       0.11      0.09      0.10       276\n",
      "        grindcore       0.74      0.77      0.76       203\n",
      "           groove       0.06      0.10      0.08       136\n",
      "           grunge       0.13      0.13      0.13       196\n",
      "           guitar       0.18      0.16      0.17       209\n",
      "            happy       0.29      0.29      0.29       225\n",
      "        hard-rock       0.06      0.06      0.06       233\n",
      "         hardcore       0.17      0.17      0.17       190\n",
      "        hardstyle       0.32      0.40      0.35       163\n",
      "      heavy-metal       0.23      0.24      0.23       185\n",
      "          hip-hop       0.28      0.21      0.24       257\n",
      "       honky-tonk       0.66      0.72      0.69       189\n",
      "            house       0.11      0.15      0.12       142\n",
      "              idm       0.37      0.36      0.37       205\n",
      "           indian       0.11      0.09      0.10       238\n",
      "            indie       0.07      0.08      0.08       202\n",
      "        indie-pop       0.05      0.07      0.06       151\n",
      "       industrial       0.11      0.13      0.12       164\n",
      "          iranian       0.57      0.70      0.63       133\n",
      "          j-dance       0.26      0.23      0.25       187\n",
      "           j-idol       0.37      0.40      0.39       199\n",
      "            j-pop       0.11      0.08      0.10       241\n",
      "           j-rock       0.07      0.08      0.07       169\n",
      "             jazz       0.35      0.45      0.39       174\n",
      "            k-pop       0.37      0.36      0.37       191\n",
      "             kids       0.48      0.50      0.49       198\n",
      "            latin       0.18      0.13      0.15       313\n",
      "           latino       0.03      0.03      0.03       213\n",
      "            malay       0.12      0.12      0.12       189\n",
      "         mandopop       0.21      0.22      0.21       176\n",
      "            metal       0.03      0.03      0.03       145\n",
      "        metalcore       0.24      0.27      0.26       179\n",
      "   minimal-techno       0.24      0.28      0.26       192\n",
      "              mpb       0.08      0.06      0.07       234\n",
      "          new-age       0.39      0.38      0.38       186\n",
      "            opera       0.36      0.36      0.36       188\n",
      "           pagode       0.33      0.32      0.33       207\n",
      "            party       0.39      0.39      0.39       196\n",
      "            piano       0.29      0.30      0.29       181\n",
      "              pop       0.22      0.24      0.23       187\n",
      "         pop-film       0.26      0.31      0.28       157\n",
      "        power-pop       0.30      0.25      0.27       212\n",
      "progressive-house       0.13      0.15      0.14       155\n",
      "       psych-rock       0.12      0.14      0.13       159\n",
      "             punk       0.07      0.06      0.07       240\n",
      "        punk-rock       0.02      0.03      0.03       154\n",
      "            r-n-b       0.07      0.10      0.08       147\n",
      "           reggae       0.09      0.10      0.09       174\n",
      "        reggaeton       0.01      0.01      0.01        98\n",
      "             rock       0.11      0.17      0.13       124\n",
      "      rock-n-roll       0.20      0.21      0.21       195\n",
      "       rockabilly       0.16      0.17      0.16       192\n",
      "          romance       0.74      0.76      0.75       187\n",
      "              sad       0.11      0.13      0.12       177\n",
      "            salsa       0.47      0.51      0.49       187\n",
      "            samba       0.23      0.25      0.24       175\n",
      "        sertanejo       0.30      0.39      0.34       158\n",
      "       show-tunes       0.23      0.27      0.25       177\n",
      "singer-songwriter       0.02      0.02      0.02       236\n",
      "              ska       0.19      0.25      0.22       167\n",
      "            sleep       0.84      0.87      0.86       183\n",
      "       songwriter       0.03      0.05      0.04       149\n",
      "             soul       0.21      0.27      0.24       156\n",
      "          spanish       0.12      0.13      0.12       172\n",
      "            study       0.50      0.63      0.56       165\n",
      "          swedish       0.18      0.16      0.17       194\n",
      "        synth-pop       0.09      0.11      0.10       177\n",
      "            tango       0.56      0.51      0.54       204\n",
      "           techno       0.11      0.11      0.11       170\n",
      "           trance       0.27      0.34      0.30       166\n",
      "         trip-hop       0.15      0.17      0.16       169\n",
      "          turkish       0.16      0.18      0.17       184\n",
      "      world-music       0.25      0.31      0.27       160\n",
      "\n",
      "         accuracy                           0.23     22800\n",
      "        macro avg       0.23      0.24      0.23     22800\n",
      "     weighted avg       0.23      0.23      0.23     22800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = tree_classifier.predict(X_test)\n",
    "\n",
    "classificationreport=classification_report(y_pred,y_test)\n",
    "print(classificationreport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22964912280701755"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy =accuracy_score(y_pred,y_test)           # calculating accuracy\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to improve that base accuracy. Lets try grid search for an optimal depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth': [3, 5, 7, 10]}\n",
    "grid_search = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_max_depth = grid_search.best_params_['max_depth']\n",
    "\n",
    "# Use the best hyperparameters to train the pruned tree\n",
    "pruned_tree = DecisionTreeClassifier(max_depth=best_max_depth)\n",
    "pruned_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_pruned = pruned_tree.predict(X_test)\n",
    "\n",
    "accuracy_pruned = accuracy_score(y_test, y_pred_pruned)\n",
    "confusion_mat_pruned = confusion_matrix(y_test, y_pred_pruned)\n",
    "classification_rep_pruned = classification_report(y_test, y_pred_pruned)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_pruned}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_mat_pruned}\")\n",
    "print(f\"Classification Report:\\n{classification_rep_pruned}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy still isn't great. Lets try binning some of our attributes. This has a trade off of some information loss, but having the precise value of some of our attributes isn't neccessary.\n",
    "\n",
    "Let's bin these variables : popularity, duration_ms, danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, and tempo. We set the bins based on the data description given in the readme file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make new dataframe so that we dont mess up the old one\n",
    "X_new = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_bins = [0, 25, 50, 75, 100]\n",
    "popularity_labels = ['Very Low', 'Low', 'Moderate', 'High']\n",
    "\n",
    "duration_bins = [0, 180000, 200000, 220000, float('inf')]\n",
    "duration_labels = ['Short', 'Medium', 'Long', 'Very Long']\n",
    "\n",
    "danceability_bins = [0, 0.5, 0.7, 0.8, 1.0]\n",
    "danceability_labels = ['Low', 'Moderate', 'High', 'Very High']\n",
    "\n",
    "energy_bins = [0, 0.4, 0.6, 0.8, 1.0]\n",
    "energy_labels = ['Low', 'Moderate', 'High', 'Very High']\n",
    "\n",
    "loudness_bins = [-float('inf'), -8.0, -6.0, -4.0, 0]\n",
    "loudness_labels = ['Very Low', 'Low', 'Moderate', 'High']\n",
    "\n",
    "speechiness_bins = [0, 0.33, 0.66, 1.0]\n",
    "speechiness_labels = ['Music', 'Mixed', 'Speech']\n",
    "\n",
    "acousticness_bins = [0, 0.2, 0.4, 0.6, 1.0]\n",
    "acousticness_labels = ['Low', 'Moderate', 'High', 'Very High']\n",
    "\n",
    "instrumentalness_bins = [0, 0.2, 0.4, 0.6, 1.0]\n",
    "instrumentalness_labels = ['Low', 'Moderate', 'High', 'Very High']\n",
    "\n",
    "liveness_bins = [0, 0.2, 0.4, 0.6, 1.0]\n",
    "liveness_labels = ['Low', 'Moderate', 'High', 'Very High']\n",
    "\n",
    "valence_bins = [0, 0.25, 0.5, 0.75, 1.0]\n",
    "valence_labels = ['Low', 'Moderate', 'High', 'Very High']\n",
    "\n",
    "tempo_bins = [0, 90, 110, 130, float('inf')]\n",
    "tempo_labels = ['Very Slow', 'Slow', 'Moderate', 'Fast']\n",
    "\n",
    "X_new['popularity_bin'] = pd.cut(X_new['popularity'], bins=popularity_bins, labels=popularity_labels)\n",
    "X_new['duration_bin'] = pd.cut(X_new['duration_ms'], bins=duration_bins, labels=duration_labels)\n",
    "X_new['danceability_bin'] = pd.cut(X_new['danceability'], bins=danceability_bins, labels=danceability_labels)\n",
    "X_new['energy_bin'] = pd.cut(X_new['energy'], bins=energy_bins, labels=energy_labels)\n",
    "X_new['loudness_bin'] = pd.cut(X_new['loudness'], bins=loudness_bins, labels=loudness_labels)\n",
    "X_new['speechiness_bin'] = pd.cut(X_new['speechiness'], bins=speechiness_bins, labels=speechiness_labels)\n",
    "X_new['acousticness_bin'] = pd.cut(X_new['acousticness'], bins=acousticness_bins, labels=acousticness_labels)\n",
    "X_new['instrumentalness_bin'] = pd.cut(X_new['instrumentalness'], bins=instrumentalness_bins, labels=instrumentalness_labels)\n",
    "X_new['liveness_bin'] = pd.cut(X_new['liveness'], bins=liveness_bins, labels=liveness_labels)\n",
    "X_new['valence_bin'] = pd.cut(X_new['valence'], bins=valence_bins, labels=valence_labels)\n",
    "X_new['tempo_bin'] = pd.cut(X_new['tempo'], bins=tempo_bins, labels=tempo_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new.drop(['popularity', 'duration_ms', 'danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', \n",
    "            'liveness', 'valence', 'tempo'], axis=1, inplace=True)\n",
    "#need numerical not categorical data\n",
    "label_encoder = LabelEncoder()\n",
    "X_new_encoded = X_new.apply(label_encoder.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {'max_depth': [3, 5, 7, 10]}\n",
    "grid_search = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_max_depth = grid_search.best_params_['max_depth']\n",
    "\n",
    "# Use the best hyperparameters to train the pruned tree\n",
    "pruned_binned_tree = DecisionTreeClassifier(max_depth=best_max_depth)\n",
    "pruned_binned_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_pruned = pruned_binned_tree.predict(X_test)\n",
    "\n",
    "accuracy_pruned_binned = accuracy_score(y_test, y_pred_pruned)\n",
    "confusion_mat_pruned_binned = confusion_matrix(y_test, y_pred_pruned)\n",
    "classification_rep_pruned_binned = classification_report(y_test, y_pred_pruned)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_pruned_binned}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_mat_pruned_binned}\")\n",
    "print(f\"Classification Report:\\n{classification_rep_pruned_binned}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after binning and re-prunning our tree, we still are stuck at below 25% accuracy. Since we have seemingly exhausted our options for improving our tree, we can safely assume that decision tree is not a great algorithm for our goal. Alternatively, maybe our data just is not capable of making a good prediction overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_names = list(X.columns)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(pruned_tree, filled=True, feature_names=feature_names, class_names=list(map(str, pruned_tree.classes_)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nb = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_svm = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp = df.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
