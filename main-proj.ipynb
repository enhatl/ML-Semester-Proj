{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/enhatl/ML-Semester-Proj/main/dataset.csv'\n",
    "df = pd.read_csv(url,index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt = df.copy() #make copy so that we can prepare the data correctly\n",
    "df_dt = df_dt.dropna(axis = 0) #remove na values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique variable, will not be useful to us\n",
    "df_dt = df_dt.drop('track_id', axis=1)\n",
    "#album name and track name are not going to be useful either\n",
    "df_dt = df_dt.drop(['album_name','track_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#artist name can be useful, but need to get them as numerical values\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "#We are assuming the first artist is the main artist and will give the most information.\n",
    "df_dt['artist_encoded'] = df_dt['artists'].str.split(',').str[0].str.strip()  #Extract first artist\n",
    "df_dt['artist_encoded'] = label_encoder.fit_transform(df_dt['artist_encoded'])  #Apply label encoding\n",
    "X = df_dt.drop(['track_genre', 'artists'], axis=1) #dont need artists column anymore\n",
    "y = df_dt['track_genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_classifier = DecisionTreeClassifier()\n",
    "tree_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         acoustic       0.09      0.08      0.09       119\n",
      "         afrobeat       0.27      0.25      0.26       112\n",
      "         alt-rock       0.03      0.01      0.02       222\n",
      "      alternative       0.07      0.06      0.07       136\n",
      "          ambient       0.21      0.22      0.21       105\n",
      "            anime       0.15      0.12      0.13       117\n",
      "      black-metal       0.59      0.46      0.52       123\n",
      "        bluegrass       0.27      0.29      0.28        90\n",
      "            blues       0.13      0.10      0.11       135\n",
      "           brazil       0.05      0.03      0.04       176\n",
      "        breakbeat       0.31      0.34      0.33       102\n",
      "          british       0.06      0.06      0.06       120\n",
      "         cantopop       0.27      0.26      0.26       105\n",
      "    chicago-house       0.43      0.46      0.44       101\n",
      "         children       0.28      0.32      0.30        74\n",
      "            chill       0.15      0.15      0.15       109\n",
      "        classical       0.57      0.46      0.51       124\n",
      "             club       0.20      0.21      0.20        91\n",
      "           comedy       0.83      0.86      0.85        96\n",
      "          country       0.42      0.39      0.40       103\n",
      "            dance       0.34      0.24      0.28       127\n",
      "        dancehall       0.22      0.20      0.21       101\n",
      "      death-metal       0.22      0.21      0.21       100\n",
      "       deep-house       0.16      0.10      0.13       137\n",
      "   detroit-techno       0.50      0.49      0.50       105\n",
      "            disco       0.14      0.15      0.14       100\n",
      "           disney       0.25      0.27      0.26       109\n",
      "    drum-and-bass       0.41      0.36      0.38       103\n",
      "              dub       0.05      0.03      0.04       147\n",
      "          dubstep       0.02      0.02      0.02        84\n",
      "              edm       0.03      0.02      0.03       153\n",
      "          electro       0.12      0.10      0.11       123\n",
      "       electronic       0.04      0.05      0.05        84\n",
      "              emo       0.14      0.12      0.13       116\n",
      "             folk       0.06      0.05      0.05       116\n",
      "            forro       0.28      0.27      0.28        96\n",
      "           french       0.12      0.15      0.14        80\n",
      "             funk       0.19      0.17      0.18       107\n",
      "           garage       0.10      0.12      0.11        83\n",
      "           german       0.21      0.23      0.22        91\n",
      "           gospel       0.17      0.26      0.20        84\n",
      "             goth       0.13      0.12      0.12       107\n",
      "        grindcore       0.78      0.75      0.77        96\n",
      "           groove       0.11      0.11      0.11       113\n",
      "           grunge       0.15      0.12      0.13       106\n",
      "           guitar       0.20      0.29      0.24        84\n",
      "            happy       0.31      0.36      0.34       105\n",
      "        hard-rock       0.06      0.05      0.05       105\n",
      "         hardcore       0.17      0.16      0.16       104\n",
      "        hardstyle       0.34      0.43      0.38        89\n",
      "      heavy-metal       0.36      0.38      0.37       109\n",
      "          hip-hop       0.23      0.22      0.23       116\n",
      "       honky-tonk       0.61      0.67      0.64        88\n",
      "            house       0.10      0.15      0.12        61\n",
      "              idm       0.38      0.37      0.37        95\n",
      "           indian       0.16      0.12      0.14       134\n",
      "            indie       0.05      0.06      0.06       104\n",
      "        indie-pop       0.08      0.12      0.09        68\n",
      "       industrial       0.10      0.11      0.11        81\n",
      "          iranian       0.56      0.72      0.63        69\n",
      "          j-dance       0.33      0.32      0.32       116\n",
      "           j-idol       0.38      0.37      0.37       104\n",
      "            j-pop       0.15      0.12      0.14       122\n",
      "           j-rock       0.06      0.07      0.07        67\n",
      "             jazz       0.40      0.46      0.43        87\n",
      "            k-pop       0.34      0.36      0.35        94\n",
      "             kids       0.52      0.56      0.54       111\n",
      "            latin       0.09      0.06      0.07       154\n",
      "           latino       0.03      0.03      0.03       112\n",
      "            malay       0.05      0.06      0.06       100\n",
      "         mandopop       0.14      0.14      0.14        97\n",
      "            metal       0.01      0.02      0.01        64\n",
      "        metalcore       0.23      0.30      0.26        84\n",
      "   minimal-techno       0.31      0.30      0.31        99\n",
      "              mpb       0.05      0.05      0.05       105\n",
      "          new-age       0.41      0.47      0.44        93\n",
      "            opera       0.34      0.38      0.36        87\n",
      "           pagode       0.30      0.28      0.29       106\n",
      "            party       0.40      0.39      0.39        97\n",
      "            piano       0.28      0.24      0.26       103\n",
      "              pop       0.16      0.16      0.16        94\n",
      "         pop-film       0.30      0.31      0.30        99\n",
      "        power-pop       0.28      0.25      0.27       106\n",
      "progressive-house       0.09      0.10      0.09        77\n",
      "       psych-rock       0.13      0.16      0.14        79\n",
      "             punk       0.02      0.02      0.02        82\n",
      "        punk-rock       0.03      0.04      0.04        72\n",
      "            r-n-b       0.07      0.09      0.08        81\n",
      "           reggae       0.05      0.08      0.06        62\n",
      "        reggaeton       0.01      0.02      0.01        41\n",
      "             rock       0.19      0.23      0.21        81\n",
      "      rock-n-roll       0.22      0.20      0.21       105\n",
      "       rockabilly       0.29      0.25      0.27       102\n",
      "          romance       0.65      0.78      0.71       101\n",
      "              sad       0.06      0.06      0.06        87\n",
      "            salsa       0.58      0.58      0.58       104\n",
      "            samba       0.22      0.26      0.24        94\n",
      "        sertanejo       0.32      0.32      0.32        94\n",
      "       show-tunes       0.21      0.22      0.22        89\n",
      "singer-songwriter       0.02      0.02      0.02       110\n",
      "              ska       0.13      0.15      0.14        86\n",
      "            sleep       0.82      0.84      0.83        87\n",
      "       songwriter       0.00      0.00      0.00        47\n",
      "             soul       0.17      0.27      0.21        52\n",
      "          spanish       0.15      0.17      0.16        87\n",
      "            study       0.57      0.55      0.56       102\n",
      "          swedish       0.09      0.12      0.10        75\n",
      "        synth-pop       0.16      0.16      0.16        86\n",
      "            tango       0.50      0.54      0.52        99\n",
      "           techno       0.07      0.07      0.07        88\n",
      "           trance       0.26      0.33      0.29        86\n",
      "         trip-hop       0.24      0.23      0.24       103\n",
      "          turkish       0.18      0.19      0.19       101\n",
      "      world-music       0.21      0.22      0.22        99\n",
      "\n",
      "         accuracy                           0.23     11400\n",
      "        macro avg       0.23      0.24      0.23     11400\n",
      "     weighted avg       0.23      0.23      0.23     11400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = tree_classifier.predict(X_test)\n",
    "\n",
    "classificationreport=classification_report(y_pred,y_test)\n",
    "print(classificationreport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22964912280701755"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy =accuracy_score(y_pred,y_test)           # calculating accuracy\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to improve that base accuracy. Lets try grid search for an optimal depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth': [3, 5, 7, 10]}\n",
    "grid_search = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_max_depth = grid_search.best_params_['max_depth']\n",
    "\n",
    "# Use the best hyperparameters to train the pruned tree\n",
    "pruned_tree = DecisionTreeClassifier(max_depth=best_max_depth)\n",
    "pruned_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_pruned = pruned_tree.predict(X_test)\n",
    "\n",
    "accuracy_pruned = accuracy_score(y_test, y_pred_pruned)\n",
    "confusion_mat_pruned = confusion_matrix(y_test, y_pred_pruned)\n",
    "classification_rep_pruned = classification_report(y_test, y_pred_pruned)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_pruned}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_mat_pruned}\")\n",
    "print(f\"Classification Report:\\n{classification_rep_pruned}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy still isn't great. Lets try binning some of our attributes. This has a trade off of some information loss, but having the precise value of some of our attributes isn't neccessary.\n",
    "\n",
    "Let's bin these variables : popularity, duration_ms, danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, and tempo. We set the bins based on the data description given in the readme file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make new dataframe so that we dont mess up the old one\n",
    "X_new = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_bins = [0, 25, 50, 75, 100]\n",
    "popularity_labels = ['Very Low', 'Low', 'Moderate', 'High']\n",
    "\n",
    "duration_bins = [0, 180000, 200000, 220000, float('inf')]\n",
    "duration_labels = ['Short', 'Medium', 'Long', 'Very Long']\n",
    "\n",
    "danceability_bins = [0, 0.5, 0.7, 0.8, 1.0]\n",
    "danceability_labels = ['Low', 'Moderate', 'High', 'Very High']\n",
    "\n",
    "energy_bins = [0, 0.4, 0.6, 0.8, 1.0]\n",
    "energy_labels = ['Low', 'Moderate', 'High', 'Very High']\n",
    "\n",
    "loudness_bins = [-float('inf'), -8.0, -6.0, -4.0, 0]\n",
    "loudness_labels = ['Very Low', 'Low', 'Moderate', 'High']\n",
    "\n",
    "speechiness_bins = [0, 0.33, 0.66, 1.0]\n",
    "speechiness_labels = ['Music', 'Mixed', 'Speech']\n",
    "\n",
    "acousticness_bins = [0, 0.2, 0.4, 0.6, 1.0]\n",
    "acousticness_labels = ['Low', 'Moderate', 'High', 'Very High']\n",
    "\n",
    "instrumentalness_bins = [0, 0.2, 0.4, 0.6, 1.0]\n",
    "instrumentalness_labels = ['Low', 'Moderate', 'High', 'Very High']\n",
    "\n",
    "liveness_bins = [0, 0.2, 0.4, 0.6, 1.0]\n",
    "liveness_labels = ['Low', 'Moderate', 'High', 'Very High']\n",
    "\n",
    "valence_bins = [0, 0.25, 0.5, 0.75, 1.0]\n",
    "valence_labels = ['Low', 'Moderate', 'High', 'Very High']\n",
    "\n",
    "tempo_bins = [0, 90, 110, 130, float('inf')]\n",
    "tempo_labels = ['Very Slow', 'Slow', 'Moderate', 'Fast']\n",
    "\n",
    "X_new['popularity_bin'] = pd.cut(X_new['popularity'], bins=popularity_bins, labels=popularity_labels)\n",
    "X_new['duration_bin'] = pd.cut(X_new['duration_ms'], bins=duration_bins, labels=duration_labels)\n",
    "X_new['danceability_bin'] = pd.cut(X_new['danceability'], bins=danceability_bins, labels=danceability_labels)\n",
    "X_new['energy_bin'] = pd.cut(X_new['energy'], bins=energy_bins, labels=energy_labels)\n",
    "X_new['loudness_bin'] = pd.cut(X_new['loudness'], bins=loudness_bins, labels=loudness_labels)\n",
    "X_new['speechiness_bin'] = pd.cut(X_new['speechiness'], bins=speechiness_bins, labels=speechiness_labels)\n",
    "X_new['acousticness_bin'] = pd.cut(X_new['acousticness'], bins=acousticness_bins, labels=acousticness_labels)\n",
    "X_new['instrumentalness_bin'] = pd.cut(X_new['instrumentalness'], bins=instrumentalness_bins, labels=instrumentalness_labels)\n",
    "X_new['liveness_bin'] = pd.cut(X_new['liveness'], bins=liveness_bins, labels=liveness_labels)\n",
    "X_new['valence_bin'] = pd.cut(X_new['valence'], bins=valence_bins, labels=valence_labels)\n",
    "X_new['tempo_bin'] = pd.cut(X_new['tempo'], bins=tempo_bins, labels=tempo_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new.drop(['popularity', 'duration_ms', 'danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', \n",
    "            'liveness', 'valence', 'tempo'], axis=1, inplace=True)\n",
    "#need numerical not categorical data\n",
    "label_encoder = LabelEncoder()\n",
    "X_new_encoded = X_new.apply(label_encoder.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {'max_depth': [3, 5, 7, 10]}\n",
    "grid_search = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_max_depth = grid_search.best_params_['max_depth']\n",
    "\n",
    "# Use the best hyperparameters to train the pruned tree\n",
    "pruned_binned_tree = DecisionTreeClassifier(max_depth=best_max_depth)\n",
    "pruned_binned_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_pruned = pruned_binned_tree.predict(X_test)\n",
    "\n",
    "accuracy_pruned_binned = accuracy_score(y_test, y_pred_pruned)\n",
    "confusion_mat_pruned_binned = confusion_matrix(y_test, y_pred_pruned)\n",
    "classification_rep_pruned_binned = classification_report(y_test, y_pred_pruned)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_pruned_binned}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_mat_pruned_binned}\")\n",
    "print(f\"Classification Report:\\n{classification_rep_pruned_binned}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after binning and re-prunning our tree, we still are stuck at below 25% accuracy. Since we have seemingly exhausted our options for improving our tree, we can safely assume that decision tree is not a great algorithm for our goal. Alternatively, maybe our data just is not capable of making a good prediction overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_names = list(X.columns)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(pruned_tree, filled=True, feature_names=feature_names, class_names=list(map(str, pruned_tree.classes_)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nb = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_svm = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp = df.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
